{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T14:59:05.607648Z","iopub.execute_input":"2023-12-14T14:59:05.607990Z","iopub.status.idle":"2023-12-14T14:59:05.619233Z","shell.execute_reply.started":"2023-12-14T14:59:05.607957Z","shell.execute_reply":"2023-12-14T14:59:05.618272Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nimport tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:06.203073Z","iopub.execute_input":"2023-12-14T14:59:06.203457Z","iopub.status.idle":"2023-12-14T14:59:09.872466Z","shell.execute_reply.started":"2023-12-14T14:59:06.203430Z","shell.execute_reply":"2023-12-14T14:59:09.871411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:09.874588Z","iopub.execute_input":"2023-12-14T14:59:09.875781Z","iopub.status.idle":"2023-12-14T14:59:09.890434Z","shell.execute_reply.started":"2023-12-14T14:59:09.875743Z","shell.execute_reply":"2023-12-14T14:59:09.889247Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:09.892621Z","iopub.execute_input":"2023-12-14T14:59:09.892863Z","iopub.status.idle":"2023-12-14T14:59:09.913911Z","shell.execute_reply.started":"2023-12-14T14:59:09.892842Z","shell.execute_reply":"2023-12-14T14:59:09.913123Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data[\"Family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\ntrain_data = train_data.drop([\"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:10.141305Z","iopub.execute_input":"2023-12-14T14:59:10.141615Z","iopub.status.idle":"2023-12-14T14:59:10.148823Z","shell.execute_reply.started":"2023-12-14T14:59:10.141594Z","shell.execute_reply":"2023-12-14T14:59:10.147520Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:10.576959Z","iopub.execute_input":"2023-12-14T14:59:10.577293Z","iopub.status.idle":"2023-12-14T14:59:10.586299Z","shell.execute_reply.started":"2023-12-14T14:59:10.577271Z","shell.execute_reply":"2023-12-14T14:59:10.585180Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nSex              0\nAge            177\nFare             0\nEmbarked         2\nFamily           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train_data[train_data[\"Embarked\"].notna()]\nX_train, y_train = train_data[train_data.columns[2:]], train_data[\"Survived\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:10.877165Z","iopub.execute_input":"2023-12-14T14:59:10.877683Z","iopub.status.idle":"2023-12-14T14:59:10.883687Z","shell.execute_reply.started":"2023-12-14T14:59:10.877655Z","shell.execute_reply":"2023-12-14T14:59:10.882570Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ct = ColumnTransformer([(\"fillMedian\", SimpleImputer(strategy=\"median\"), [\"Age\"]),\n                       (\"ohe\", OneHotEncoder(), [\"Sex\", \"Embarked\"]),\n                       (\"ss\", StandardScaler(), [\"Fare\"])],\n                      remainder=\"passthrough\")\np = Pipeline([(\"ct\", ct)])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:11.148950Z","iopub.execute_input":"2023-12-14T14:59:11.149481Z","iopub.status.idle":"2023-12-14T14:59:11.154125Z","shell.execute_reply.started":"2023-12-14T14:59:11.149456Z","shell.execute_reply":"2023-12-14T14:59:11.152937Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = p.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:11.430872Z","iopub.execute_input":"2023-12-14T14:59:11.431202Z","iopub.status.idle":"2023-12-14T14:59:11.449525Z","shell.execute_reply.started":"2023-12-14T14:59:11.431179Z","shell.execute_reply":"2023-12-14T14:59:11.448584Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:11.732638Z","iopub.execute_input":"2023-12-14T14:59:11.733553Z","iopub.status.idle":"2023-12-14T14:59:11.739559Z","shell.execute_reply.started":"2023-12-14T14:59:11.733507Z","shell.execute_reply":"2023-12-14T14:59:11.738614Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## kNN","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    \"n_neighbors\": [1, 5, 10, 20, 50]\n}\nknn_grid = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs=-1)\nknn_grid.fit(X_train, y_train)\nprint(knn_grid.best_params_)\ngrid_prediction = knn_grid.predict(X_valid)\nprint(classification_report(y_valid, grid_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:12.457004Z","iopub.execute_input":"2023-12-14T14:59:12.457351Z","iopub.status.idle":"2023-12-14T14:59:14.031753Z","shell.execute_reply.started":"2023-12-14T14:59:12.457328Z","shell.execute_reply":"2023-12-14T14:59:14.030695Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'n_neighbors': 5}\n              precision    recall  f1-score   support\n\n           0       0.78      0.89      0.83       110\n           1       0.77      0.60      0.68        68\n\n    accuracy                           0.78       178\n   macro avg       0.78      0.75      0.76       178\nweighted avg       0.78      0.78      0.77       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Naive Bayes","metadata":{}},{"cell_type":"code","source":"nb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_valid)\nprint(classification_report(y_valid, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:14.033592Z","iopub.execute_input":"2023-12-14T14:59:14.033898Z","iopub.status.idle":"2023-12-14T14:59:14.048925Z","shell.execute_reply.started":"2023-12-14T14:59:14.033869Z","shell.execute_reply":"2023-12-14T14:59:14.048295Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.83      0.85      0.84       110\n           1       0.74      0.72      0.73        68\n\n    accuracy                           0.80       178\n   macro avg       0.79      0.78      0.78       178\nweighted avg       0.80      0.80      0.80       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Logistical Regression","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    \"penalty\":[None,\"l2\",\"l1\",\"elasticnet\"],\n    \"C\":[0.001, 0.01, 0.1, 1, 10, 100]\n}\nlog_grid = GridSearchCV(LogisticRegression(), param_grid, n_jobs=-1)\nlog_grid.fit(X_train, y_train)\nprint(log_grid.best_params_)\ngrid_prediction = log_grid.predict(X_valid)\nprint(classification_report(y_valid, grid_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:14.049801Z","iopub.execute_input":"2023-12-14T14:59:14.050717Z","iopub.status.idle":"2023-12-14T14:59:14.483895Z","shell.execute_reply.started":"2023-12-14T14:59:14.050694Z","shell.execute_reply":"2023-12-14T14:59:14.483012Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n60 fits failed out of a total of 120.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.79180538 0.62588398        nan        nan 0.79180538 0.76521225\n        nan        nan 0.79180538 0.79464198        nan        nan\n 0.79180538 0.79602088        nan        nan 0.79180538 0.79462228\n        nan        nan 0.79180538 0.79180538        nan        nan]\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'C': 1, 'penalty': 'l2'}\n              precision    recall  f1-score   support\n\n           0       0.82      0.88      0.85       110\n           1       0.78      0.69      0.73        68\n\n    accuracy                           0.81       178\n   macro avg       0.80      0.79      0.79       178\nweighted avg       0.81      0.81      0.81       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Support Vector Machines","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    \"kernel\":[\"linear\", \"rbf\", \"sigmoid\"],\n    \"C\":[0.1, 1, 10],\n    \"degree\":list(range(3,11))\n}\nsvm_grid = GridSearchCV(SVC(), param_grid, n_jobs=-1)\nsvm_grid.fit(X_train, y_train)\nprint(svm_grid.best_params_)\ngrid_prediction = svm_grid.predict(X_valid)\nprint(classification_report(y_valid, grid_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:59:14.486143Z","iopub.execute_input":"2023-12-14T14:59:14.486466Z","iopub.status.idle":"2023-12-14T15:02:16.442143Z","shell.execute_reply.started":"2023-12-14T14:59:14.486436Z","shell.execute_reply":"2023-12-14T15:02:16.441082Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'C': 10, 'degree': 3, 'kernel': 'rbf'}\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86       110\n           1       0.80      0.71      0.75        68\n\n    accuracy                           0.82       178\n   macro avg       0.82      0.80      0.80       178\nweighted avg       0.82      0.82      0.82       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    \"n_estimators\":[100, 200, 500],\n    \"criterion\":[\"gini\",\"entropy\",\"log_loss\"]\n}   \nrfc_grid = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1)\nrfc_grid.fit(X_train, y_train)\nprint(rfc_grid.best_params_)\ngrid_prediction = rfc_grid.predict(X_valid)\nprint(classification_report(y_valid, grid_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:02:16.444075Z","iopub.execute_input":"2023-12-14T15:02:16.444516Z","iopub.status.idle":"2023-12-14T15:02:24.884955Z","shell.execute_reply.started":"2023-12-14T15:02:16.444481Z","shell.execute_reply":"2023-12-14T15:02:24.884109Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{'criterion': 'entropy', 'n_estimators': 500}\n              precision    recall  f1-score   support\n\n           0       0.83      0.87      0.85       110\n           1       0.78      0.72      0.75        68\n\n    accuracy                           0.81       178\n   macro avg       0.81      0.80      0.80       178\nweighted avg       0.81      0.81      0.81       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    \"max_depth\": range(2, 10, 1),\n    \"n_estimators\":range(40, 201, 40),\n    \"learning_rate\":[0.5, 0.1,0.05,0.01]\n}\nboost_grid = GridSearchCV(XGBClassifier(), param_grid, scoring=\"roc_auc\", cv=10, n_jobs=-1)\nboost_grid.fit(X_train, y_train)\nprint(boost_grid.best_params_)\ngrid_prediction = boost_grid.predict(X_valid)\nprint(classification_report(y_valid, grid_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:02:24.886078Z","iopub.execute_input":"2023-12-14T15:02:24.886407Z","iopub.status.idle":"2023-12-14T15:02:51.213784Z","shell.execute_reply.started":"2023-12-14T15:02:24.886378Z","shell.execute_reply":"2023-12-14T15:02:51.212850Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 40}\n              precision    recall  f1-score   support\n\n           0       0.80      0.94      0.87       110\n           1       0.86      0.63      0.73        68\n\n    accuracy                           0.82       178\n   macro avg       0.83      0.78      0.80       178\nweighted avg       0.83      0.82      0.81       178\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tensorflow","metadata":{}},{"cell_type":"code","source":"def train_model_split(X_train, y_train, num_nodes, dropout_prob, learning_rate, batch_size, epochs):\n    neuralnet = tf.keras.Sequential([\n        tf.keras.layers.Dense(num_nodes, activation=\"relu\", input_shape=(9,)),\n        tf.keras.layers.Dropout(dropout_prob),\n        tf.keras.layers.Dense(num_nodes, activation=\"relu\"),\n        tf.keras.layers.Dropout(dropout_prob),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n    ])\n    neuralnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n                     loss=\"binary_crossentropy\",\n                     metrics=[\"accuracy\"])\n    history = neuralnet.fit(X_train,\n                            y_train,\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            validation_split=0.2,\n                            verbose=0\n                           )\n    return neuralnet, history","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:02:51.215084Z","iopub.execute_input":"2023-12-14T15:02:51.215432Z","iopub.status.idle":"2023-12-14T15:02:51.222551Z","shell.execute_reply.started":"2023-12-14T15:02:51.215400Z","shell.execute_reply":"2023-12-14T15:02:51.221592Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_model_data(X_train, y_train, num_nodes, dropout_prob, learning_rate, batch_size, epochs):\n    neuralnet = tf.keras.Sequential([\n        tf.keras.layers.Dense(num_nodes, activation=\"relu\", input_shape=(9,)),\n        tf.keras.layers.Dropout(dropout_prob),\n        tf.keras.layers.Dense(num_nodes, activation=\"relu\"),\n        tf.keras.layers.Dropout(dropout_prob),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n    ])\n    neuralnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n                     loss=\"binary_crossentropy\",\n                     metrics=[\"accuracy\"])\n    history = neuralnet.fit(X_train,\n                            y_train,\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            validation_data=(X_valid, y_valid),\n                            verbose=0\n                           )\n    return neuralnet, history","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:02:51.224685Z","iopub.execute_input":"2023-12-14T15:02:51.225374Z","iopub.status.idle":"2023-12-14T15:02:51.245662Z","shell.execute_reply.started":"2023-12-14T15:02:51.225349Z","shell.execute_reply":"2023-12-14T15:02:51.244961Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"least_validation_loss_split = float(\"inf\")\nleast_validation_loss_data = float(\"inf\")\nleast_loss_model_split = None\nleast_loss_model_data = None\n\nepochs = 100\nfor num_nodes in [16,32,64]:\n  for dropout_prob in [0,0.2]:\n    for learning_rate in [0.01,0.005,0.001]:\n      for batch_size in [32,64,128]:\n        print(f\"nodes: {num_nodes}, dropout: {dropout_prob}, learning rate: {learning_rate}, batch size: {batch_size}\")\n        print(\"validation_split = 0.2\")\n        model,history = train_model_split(X_train,y_train,num_nodes,dropout_prob,learning_rate,batch_size,epochs)\n        val_loss, val_accuracy = model.evaluate(X_valid,y_valid)\n        if val_loss < least_validation_loss_split:\n          least_validation_loss_split = val_loss\n          least_loss_model_split = model\n\n        print(\"validation_data = (X_valid,y_valid)\")\n        model,history = train_model_data(X_train,y_train,num_nodes,dropout_prob,learning_rate,batch_size,epochs)\n        val_loss, val_accuracy = model.evaluate(X_valid,y_valid)\n        if val_loss < least_validation_loss_data:\n          least_validation_loss_data = val_loss\n          least_loss_model_data = model","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:02:51.246498Z","iopub.execute_input":"2023-12-14T15:02:51.247430Z","iopub.status.idle":"2023-12-14T15:13:28.067749Z","shell.execute_reply.started":"2023-12-14T15:02:51.247405Z","shell.execute_reply":"2023-12-14T15:13:28.067151Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"nodes: 16, dropout: 0, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8258\nnodes: 16, dropout: 0, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8315\nnodes: 16, dropout: 0, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8090\nnodes: 16, dropout: 0, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8146\nnodes: 16, dropout: 0, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8427\nnodes: 16, dropout: 0, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8258\nnodes: 16, dropout: 0, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8258\nnodes: 16, dropout: 0, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7978\nnodes: 16, dropout: 0, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8090\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7921\nnodes: 16, dropout: 0.2, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8371\nnodes: 16, dropout: 0.2, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8202\nnodes: 16, dropout: 0.2, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8427\nnodes: 16, dropout: 0.2, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8202\nnodes: 16, dropout: 0.2, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8427\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8258\nnodes: 16, dropout: 0.2, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8371\nnodes: 16, dropout: 0.2, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8090\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8315\nnodes: 16, dropout: 0.2, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8034\nnodes: 16, dropout: 0.2, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7978\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8146\nnodes: 32, dropout: 0, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7753\nnodes: 32, dropout: 0, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8202\nnodes: 32, dropout: 0, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.8090\nnodes: 32, dropout: 0, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8315\nnodes: 32, dropout: 0, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8483\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8202\nnodes: 32, dropout: 0, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8427\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8427\nnodes: 32, dropout: 0, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8202\nnodes: 32, dropout: 0, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8034\nnodes: 32, dropout: 0, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8090\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8315\nnodes: 32, dropout: 0.2, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8202\nnodes: 32, dropout: 0.2, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8146\nnodes: 32, dropout: 0.2, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8315\nnodes: 32, dropout: 0.2, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8258\nnodes: 32, dropout: 0.2, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8427\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8315\nnodes: 32, dropout: 0.2, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8146\nnodes: 32, dropout: 0.2, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8258\nnodes: 32, dropout: 0.2, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8315\nnodes: 32, dropout: 0.2, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8090\nnodes: 64, dropout: 0, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.8483\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.8202\nnodes: 64, dropout: 0, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.8090\nnodes: 64, dropout: 0, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8258\nnodes: 64, dropout: 0, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8146\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.8202\nnodes: 64, dropout: 0, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8483\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8202\nnodes: 64, dropout: 0, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7809\nnodes: 64, dropout: 0, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8315\nnodes: 64, dropout: 0, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.8202\nnodes: 64, dropout: 0, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8371\nnodes: 64, dropout: 0.2, learning rate: 0.01, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.8258\nnodes: 64, dropout: 0.2, learning rate: 0.01, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8315\nnodes: 64, dropout: 0.2, learning rate: 0.01, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8315\nnodes: 64, dropout: 0.2, learning rate: 0.005, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.8483\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8202\nnodes: 64, dropout: 0.2, learning rate: 0.005, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8315\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8258\nnodes: 64, dropout: 0.2, learning rate: 0.005, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8258\nnodes: 64, dropout: 0.2, learning rate: 0.001, batch size: 32\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8371\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8258\nnodes: 64, dropout: 0.2, learning rate: 0.001, batch size: 64\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8258\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8315\nnodes: 64, dropout: 0.2, learning rate: 0.001, batch size: 128\nvalidation_split = 0.2\n6/6 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8202\nvalidation_data = (X_valid,y_valid)\n6/6 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8202\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Choosing Model","metadata":{}},{"cell_type":"code","source":"model = VotingClassifier([\n    (\"1\",knn_grid),\n    (\"2\",nb),\n    (\"3\",log_grid),\n    (\"4\",svm_grid),\n    (\"5\",rfc_grid),\n    (\"6\",boost_grid)\n])\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_valid)\nroc_auc_1 = roc_auc_score(y_valid, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:13:28.068936Z","iopub.execute_input":"2023-12-14T15:13:28.071321Z","iopub.status.idle":"2023-12-14T15:17:05.583396Z","shell.execute_reply.started":"2023-12-14T15:13:28.071290Z","shell.execute_reply":"2023-12-14T15:17:05.582620Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n60 fits failed out of a total of 120.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.79180538 0.62588398        nan        nan 0.79180538 0.76521225\n        nan        nan 0.79180538 0.79464198        nan        nan\n 0.79180538 0.79602088        nan        nan 0.79180538 0.79462228\n        nan        nan 0.79180538 0.79180538        nan        nan]\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def tensor_binarizer(lst):\n    return [1 if x[0] > 0.5 else 0 for x in lst]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.584663Z","iopub.execute_input":"2023-12-14T15:17:05.585175Z","iopub.status.idle":"2023-12-14T15:17:05.590089Z","shell.execute_reply.started":"2023-12-14T15:17:05.585149Z","shell.execute_reply":"2023-12-14T15:17:05.588860Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tf_pred1 = least_loss_model_split.predict(X_valid)\ntf_pred2 = least_loss_model_data.predict(X_valid)\ntf_pred1 = tensor_binarizer(tf_pred1)\ntf_pred2 = tensor_binarizer(tf_pred2)\nroc_auc_2 = roc_auc_score(y_valid, tf_pred1)\nroc_auc_3 = roc_auc_score(y_valid, tf_pred2)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.591247Z","iopub.execute_input":"2023-12-14T15:17:05.591498Z","iopub.status.idle":"2023-12-14T15:17:05.863470Z","shell.execute_reply.started":"2023-12-14T15:17:05.591476Z","shell.execute_reply":"2023-12-14T15:17:05.862626Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"6/6 [==============================] - 0s 2ms/step\n6/6 [==============================] - 0s 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"d = {roc_auc_1:model, roc_auc_2:least_loss_model_split, roc_auc_3:least_loss_model_data}\ntop_score = max(d.keys())\nmodel = d[top_score]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.864707Z","iopub.execute_input":"2023-12-14T15:17:05.865022Z","iopub.status.idle":"2023-12-14T15:17:05.870662Z","shell.execute_reply.started":"2023-12-14T15:17:05.864992Z","shell.execute_reply":"2023-12-14T15:17:05.869749Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"test_data[\"Family\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\npassengers = test_data[\"PassengerId\"]\ntest_data = test_data.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.871820Z","iopub.execute_input":"2023-12-14T15:17:05.872134Z","iopub.status.idle":"2023-12-14T15:17:05.884741Z","shell.execute_reply.started":"2023-12-14T15:17:05.872087Z","shell.execute_reply":"2023-12-14T15:17:05.883539Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.886398Z","iopub.execute_input":"2023-12-14T15:17:05.886981Z","iopub.status.idle":"2023-12-14T15:17:05.903938Z","shell.execute_reply.started":"2023-12-14T15:17:05.886950Z","shell.execute_reply":"2023-12-14T15:17:05.903197Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Pclass       0\nSex          0\nAge         86\nFare         1\nEmbarked     0\nFamily       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"avgfare = test_data[\"Fare\"].dropna().mean()\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(avgfare)\nprint(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.905358Z","iopub.execute_input":"2023-12-14T15:17:05.905810Z","iopub.status.idle":"2023-12-14T15:17:05.921822Z","shell.execute_reply.started":"2023-12-14T15:17:05.905785Z","shell.execute_reply":"2023-12-14T15:17:05.920980Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"     Pclass     Sex   Age      Fare Embarked  Family\n0         3    male  34.5    7.8292        Q       0\n1         3  female  47.0    7.0000        S       1\n2         2    male  62.0    9.6875        Q       0\n3         3    male  27.0    8.6625        S       0\n4         3  female  22.0   12.2875        S       2\n..      ...     ...   ...       ...      ...     ...\n413       3    male   NaN    8.0500        S       0\n414       1  female  39.0  108.9000        C       0\n415       3    male  38.5    7.2500        S       0\n416       3    male   NaN    8.0500        S       0\n417       3    male   NaN   22.3583        C       2\n\n[418 rows x 6 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = pd.DataFrame(p.fit_transform(test_data))\nprint(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.922998Z","iopub.execute_input":"2023-12-14T15:17:05.923295Z","iopub.status.idle":"2023-12-14T15:17:05.948205Z","shell.execute_reply.started":"2023-12-14T15:17:05.923261Z","shell.execute_reply":"2023-12-14T15:17:05.946919Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"        0    1    2    3    4    5         6    7    8\n0    34.5  0.0  1.0  0.0  1.0  0.0 -0.498407  3.0  0.0\n1    47.0  1.0  0.0  0.0  0.0  1.0 -0.513274  3.0  1.0\n2    62.0  0.0  1.0  0.0  1.0  0.0 -0.465088  2.0  0.0\n3    27.0  0.0  1.0  0.0  0.0  1.0 -0.483466  3.0  0.0\n4    22.0  1.0  0.0  0.0  0.0  1.0 -0.418471  3.0  2.0\n..    ...  ...  ...  ...  ...  ...       ...  ...  ...\n413  27.0  0.0  1.0  0.0  0.0  1.0 -0.494448  3.0  0.0\n414  39.0  1.0  0.0  1.0  0.0  0.0  1.313753  1.0  0.0\n415  38.5  0.0  1.0  0.0  0.0  1.0 -0.508792  3.0  0.0\n416  27.0  0.0  1.0  0.0  0.0  1.0 -0.494448  3.0  0.0\n417  27.0  0.0  1.0  1.0  0.0  0.0 -0.237906  3.0  2.0\n\n[418 rows x 9 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_pred = model.predict(test_data)\ntest_pred = tensor_binarizer(test_pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:05.949409Z","iopub.execute_input":"2023-12-14T15:17:05.949677Z","iopub.status.idle":"2023-12-14T15:17:06.128311Z","shell.execute_reply.started":"2023-12-14T15:17:05.949656Z","shell.execute_reply":"2023-12-14T15:17:06.126856Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"14/14 [==============================] - 0s 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"final = pd.DataFrame(test_pred, index=passengers)\nfinal.columns=[\"Survived\"]\nprint(final)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:06.131760Z","iopub.execute_input":"2023-12-14T15:17:06.132317Z","iopub.status.idle":"2023-12-14T15:17:06.140187Z","shell.execute_reply.started":"2023-12-14T15:17:06.132288Z","shell.execute_reply":"2023-12-14T15:17:06.139005Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"             Survived\nPassengerId          \n892                 0\n893                 0\n894                 0\n895                 0\n896                 0\n...               ...\n1305                0\n1306                1\n1307                0\n1308                0\n1309                0\n\n[418 rows x 1 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"final.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:17:06.141689Z","iopub.execute_input":"2023-12-14T15:17:06.142059Z","iopub.status.idle":"2023-12-14T15:17:06.154048Z","shell.execute_reply.started":"2023-12-14T15:17:06.142028Z","shell.execute_reply":"2023-12-14T15:17:06.152866Z"},"trusted":true},"execution_count":30,"outputs":[]}]}